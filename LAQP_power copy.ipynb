{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17bae3c",
   "metadata": {},
   "source": [
    "### Step1: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d4d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 2049280 rows\n",
      "First 5 data:    timestamp  Global_active_power  Global_reactive_power  Voltage  \\\n",
      "0        0.0                4.216                  0.418   234.84   \n",
      "1       60.0                5.360                  0.436   233.63   \n",
      "2      120.0                5.374                  0.498   233.29   \n",
      "3      180.0                5.388                  0.502   233.74   \n",
      "4      240.0                3.666                  0.528   235.68   \n",
      "\n",
      "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "0              18.4             0.0             1.0            17.0  \n",
      "1              23.0             0.0             1.0            16.0  \n",
      "2              23.0             0.0             2.0            17.0  \n",
      "3              23.0             0.0             1.0            17.0  \n",
      "4              15.8             0.0             1.0            17.0  \n",
      "Data size: 2049280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to extracted TXT file\n",
    "file_path = 'household_power_consumption.txt'\n",
    "\n",
    "# Load with ; separator, handle '?' as NaN\n",
    "data = pd.read_csv(file_path, sep=';', na_values='?')\n",
    "\n",
    "# Combine Date and Time to datetime\n",
    "data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Numerical timestamp: seconds since the earliest date\n",
    "min_dt = data['datetime'].min()\n",
    "data['timestamp'] = (data['datetime'] - min_dt).dt.total_seconds()\n",
    "\n",
    "# Relevant columns (drop Date/Time/datetime, keep numerics)\n",
    "cols = ['timestamp', 'Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "        'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "data = data[cols].dropna()  # ~1.25% missing, drop for simplicity\n",
    "full_data_size = len(data)\n",
    "\n",
    "print(f\"Dataset loaded: {data.shape[0]} rows\")\n",
    "print(f\"First 5 data: {data.head()}\")\n",
    "print(f\"Data size: {full_data_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad053a51",
   "metadata": {},
   "source": [
    "### Step2: Create a Small Offline Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56d105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample created: 2049 rows\n",
      "          timestamp  Global_active_power  Global_reactive_power  Voltage  \\\n",
      "1030580  61834800.0                1.502                  0.074   240.17   \n",
      "1815       108900.0                0.374                  0.264   245.50   \n",
      "1295977  77758620.0                0.620                  0.300   239.85   \n",
      "206669   12400140.0                0.280                  0.200   235.72   \n",
      "1048893  62933580.0                1.372                  0.054   243.95   \n",
      "\n",
      "         Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "1030580               6.4             0.0             0.0            18.0  \n",
      "1815                  1.8             0.0             2.0             0.0  \n",
      "1295977               3.0             0.0             1.0             1.0  \n",
      "206669                1.4             0.0             0.0             0.0  \n",
      "1048893               5.6             0.0             0.0            18.0  \n"
     ]
    }
   ],
   "source": [
    "sample_size = int(0.001 * len(data))  # ~2000 rows\n",
    "sample = data.sample(n=sample_size, random_state=42).copy()\n",
    "print(f\"Sample created: {sample.shape[0]} rows\")\n",
    "print(sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b378af9",
   "metadata": {},
   "source": [
    "### Step 3: Generate Query Log, training data, testing data, optimize testing data.\n",
    "直接抓query因為dimension很大的問題，result有可能會是0，因此先將範圍大概縮在中間50%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07963f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim: timestamp, min value: 0.0, max value: 124515480.0\n",
      "dim: Global_reactive_power, min value: 0.0, max value: 1.39\n",
      "dim: Voltage, min value: 223.2, max value: 254.15\n",
      "dim: Global_intensity, min value: 0.2, max value: 48.4\n",
      "dim: Sub_metering_1, min value: 0.0, max value: 88.0\n",
      "dim: Sub_metering_2, min value: 0.0, max value: 80.0\n",
      "dim: Sub_metering_3, min value: 0.0, max value: 31.0\n",
      "{'timestamp': (17291776.85886668, 123811337.46848838), 'Global_reactive_power': (0.23552149899974487, 1.259064854226316), 'Voltage': (227.93213005969142, 254.10742060721148), 'Global_intensity': (12.191277357660798, 37.15042594320554), 'Sub_metering_1': (16.263027475723394, 71.58146211867832), 'Sub_metering_2': (16.074055194117843, 69.27929219316373), 'Sub_metering_3': (3.2979140522769272, 29.557605768690035)}\n"
     ]
    }
   ],
   "source": [
    "from funcs import generate_random_query, exact_sum, sample_sum\n",
    "\n",
    "# Define dimensions (7D) and their min/max\n",
    "dimensions = ['timestamp', 'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "              'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "q = generate_random_query(data, dimensions, test = True)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e275d",
   "metadata": {},
   "source": [
    "建立query log (探討query log數量對準確率的影響 2000, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a3f0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate avg_exact by temp queries...\n",
      "Generated 2000 temp queries in 2000 attempts\n",
      "Average exact sum: avg_exact=10332.33893\n",
      "\n",
      "Generating 2000 queries...\n",
      "Generated 2000 queries in 4000 attempts\n"
     ]
    }
   ],
   "source": [
    "# Aggregate column\n",
    "agg_col = 'Global_active_power'\n",
    "\n",
    "# 設定一個avg exact讓threshold有依據\n",
    "print(\"Generate avg_exact by temp queries...\")\n",
    "temp_query_log = []\n",
    "num_queries = 2000\n",
    "attempts = 0\n",
    "max_attempts = 10000\n",
    "\n",
    "while len(temp_query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    if exact_result > 1.0:  # 會有result為0的情況，設定threshold確保result有值\n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        temp_query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "avg_exact = np.mean([temp_query['exact'] for temp_query in temp_query_log])\n",
    "print(f\"Generated {len(temp_query_log)} temp queries in {attempts} attempts\")\n",
    "print(f\"Average exact sum: {avg_exact=}\\n\")\n",
    "\n",
    "# For training: 2000 queries (as in paper)\n",
    "query_log = []\n",
    "print(\"Generating 2000 queries...\")\n",
    "while len(query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    \n",
    "    if exact_result > 0.01 * avg_exact: \n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "print(f\"Generated {len(query_log)} queries in {attempts} attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b5c4e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (23437887.053916544, 94592830.88469991),\n",
       "  'Global_reactive_power': (0.27302545355565555, 1.250669601201702),\n",
       "  'Voltage': (223.35450961185745, 247.6849221372796),\n",
       "  'Global_intensity': (7.202080358082646, 39.42943339315976),\n",
       "  'Sub_metering_1': (20.79802764885083, 87.88593920202045),\n",
       "  'Sub_metering_2': (1.44897650626439, 69.75755047009937),\n",
       "  'Sub_metering_3': (7.060985772534219, 24.443570064991455)},\n",
       " 'exact': 8065.112,\n",
       " 'estimate': 4360.5958028306495,\n",
       " 'error': 3704.5161971693506}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看任意query log\n",
    "query_log[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745dc2d",
   "metadata": {},
   "source": [
    "建立經過diversification的training data (看能不能畫經過diversification前後的圖)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d5f3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversified query log: selected 800 / 2000 entries\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "scaler_div = StandardScaler()\n",
    "\n",
    "def diversify_query_log(query_log, k):\n",
    "    \"\"\"\n",
    "    Diversify the query log using greedy max-min.\n",
    "    Features: flattened ranges + error.\n",
    "    Returns a subset of k diverse entries.\n",
    "    \"\"\"\n",
    "    # Prepare features: flatten query bounds + error\n",
    "    features = []\n",
    "    for entry in query_log:\n",
    "        vec = []\n",
    "        for dim in dimensions:\n",
    "            lower, upper = entry['query'][dim]\n",
    "            vec.extend([lower, upper])\n",
    "        vec.append(entry['error'])\n",
    "        features.append(vec)\n",
    "    \n",
    "    features = np.array(features)\n",
    "    features_norm = scaler_div.fit_transform(features)\n",
    "    \n",
    "    # Greedy max-min selection\n",
    "    selected_indices = [random.randint(0, len(features)-1)]  # Start with random\n",
    "    selected_features = features_norm[selected_indices]\n",
    "    \n",
    "    while len(selected_indices) < k:\n",
    "        # Distances from unselected to current selected set\n",
    "        dists = euclidean_distances(selected_features, features_norm)\n",
    "        min_dists = dists.min(axis=0)  # Min dist to any selected\n",
    "        # Pick the one with max min-dist (most diverse)\n",
    "        next_idx = np.argmax(min_dists)\n",
    "        selected_indices.append(next_idx)\n",
    "        selected_features = features_norm[selected_indices]\n",
    "    \n",
    "    diversified_log = [query_log[i] for i in selected_indices]\n",
    "    print(f\"Diversified query log: selected {len(diversified_log)} / {len(query_log)} entries\")\n",
    "    return diversified_log\n",
    "\n",
    "training_data_query_log = diversify_query_log(query_log, k=800) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7434d007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (17205500.378826212, 121722720.24010296),\n",
       "  'Global_reactive_power': (0.20480403207609038, 1.1807842852007648),\n",
       "  'Voltage': (224.59889203308998, 253.74687675317512),\n",
       "  'Global_intensity': (8.930670105904072, 46.54842060112646),\n",
       "  'Sub_metering_1': (3.7272973951432227, 67.14394407472119),\n",
       "  'Sub_metering_2': (0.5691467196401301, 64.15837289871862),\n",
       "  'Sub_metering_3': (0.7151272220698534, 25.907042394257218)},\n",
       " 'exact': 34743.532,\n",
       " 'estimate': 40835.57950219619,\n",
       " 'error': -6092.04750219619}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看任意diversified log\n",
    "training_data_query_log[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8bd80",
   "metadata": {},
   "source": [
    "建立testing data (不經過diversificatoin, 模擬任意query的情況)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849bc6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate testing...\n",
      "Generated 100 testing data in 100 attempts\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate testing...\")\n",
    "testing_data_query_log = []\n",
    "num_queries = 100\n",
    "attempts = 0\n",
    "max_attempts = 1000\n",
    "\n",
    "while len(testing_data_query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    if exact_result > 0.01 * avg_exact:  # 會有result為0的情況，設定threshold確保result有值\n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        testing_data_query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "avg_exact = np.mean([temp_query['exact'] for temp_query in testing_data_query_log])\n",
    "print(f\"Generated {len(testing_data_query_log)} testing data in {attempts} attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6066d",
   "metadata": {},
   "source": [
    "Check training, testing data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "642851dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  800 testing data:  100\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data: \", len(training_data_query_log), \"testing data: \",  len(testing_data_query_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac190cef",
   "metadata": {},
   "source": [
    "### Step 4: Train the Error Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4500066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input query and output x, y\n",
    "def data_split(query_log):\n",
    "    # Prepare features (flatten: lower/upper per dim) and targets (errors)\n",
    "    X = []\n",
    "    y = []\n",
    "    for entry in query_log:\n",
    "\n",
    "        vec = []\n",
    "        for dim in dimensions:\n",
    "            lower, upper = entry['query'][dim]\n",
    "            vec.extend([lower, upper])\n",
    "        X.append(vec)\n",
    "        y.append(entry['error'])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Normalize\n",
    "    X_scaled = scaler_div.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y\n",
    "\n",
    "X_train, y_train = data_split(training_data_query_log)\n",
    "X_test, y_test = data_split(testing_data_query_log)\n",
    "\n",
    "# adjust max_depth\n",
    "model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model trained.\")\n",
    "\n",
    "# 評估模型\n",
    "train_mse = np.mean((model.predict(X_train) - y_train) ** 2)\n",
    "test_mse  = np.mean((model.predict(X_test)  - y_test)  ** 2)\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test  MSE: {test_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cd6a4",
   "metadata": {},
   "source": [
    "載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "data = joblib.load(\"regression_pipeline.pkl\")\n",
    "model = data[\"model\"]\n",
    "scaler = data[\"scaler\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c9536",
   "metadata": {},
   "source": [
    "儲存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1131189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression_pipeline.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump({\n",
    "    \"model\": model,\n",
    "    \"scaler\": scaler_div\n",
    "}, \"regression_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed20f77",
   "metadata": {},
   "source": [
    "### Step 5: Estimate a New Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeb865d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAQP estimate: 562522.29\n",
      "Exact sum: 560494.03\n",
      "Relative error: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Example new 7D query (adjust ranges to sensible values based on data mins/maxes)\n",
    "new_query = {\n",
    "    'timestamp': (0, 1e8),  # e.g., first ~few months in seconds\n",
    "    'Global_reactive_power': (0.0, 0.5),\n",
    "    'Voltage': (220, 250),\n",
    "    'Global_intensity': (0, 20),\n",
    "    'Sub_metering_1': (0, 10),\n",
    "    'Sub_metering_2': (0, 5),\n",
    "    'Sub_metering_3': (0, 15)\n",
    "}\n",
    "\n",
    "# Flatten and scale\n",
    "new_vec = []\n",
    "for dim in dimensions:\n",
    "    lower, upper = new_query[dim]\n",
    "    new_vec.extend([lower, upper])\n",
    "new_vec = np.array([new_vec])\n",
    "new_scaled = scaler_div.transform(new_vec)\n",
    "\n",
    "# Predict error\n",
    "predicted_error = model.predict(new_scaled)[0]\n",
    "\n",
    "# Find error-similar historical query (closest error)\n",
    "min_diff = float('inf')\n",
    "opt_entry = None\n",
    "for entry in training_data_query_log:\n",
    "    error_diff = abs(entry['error'] - predicted_error)\n",
    "    if error_diff < min_diff:\n",
    "        min_diff = error_diff\n",
    "        opt_entry = entry\n",
    "\n",
    "# Compute final estimate\n",
    "sample_new = sample_sum(agg_col, new_query, sample, full_data_size)\n",
    "sample_opt = opt_entry['estimate']\n",
    "final_estimate = opt_entry['exact'] + (sample_new - sample_opt)\n",
    "\n",
    "print(f\"LAQP estimate: {final_estimate:.2f}\")\n",
    "# Compute exact for the same query (for debugging/small queries)\n",
    "exact = exact_sum(agg_col, new_query, data)\n",
    "print(f\"Exact sum: {exact:.2f}\")\n",
    "print(f\"Relative error: {abs(final_estimate - exact) / exact:.4f}\")\n",
    "\n",
    "# Also see how many rows match\n",
    "# mask = np.ones(len(data), dtype=bool)\n",
    "# for dim, (l, u) in new_query.items():\n",
    "#     mask &= (data[dim] >= l) & (data[dim] <= u)\n",
    "# matched_rows = mask.sum()\n",
    "# print(f\"Query matches {matched_rows:,} rows ({matched_rows / len(data):.1%} of dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a02e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimal query index: 37 (out of  800)\n",
      "Predicted error for new query: 12956.13\n",
      "Chosen historical query error: 12907.19 (diff: 48.94)\n",
      "Exact result of chosen query: 12907.19\n",
      "Predicate ranges of chosen query:\n",
      "  timestamp: [12241192.35, 101167730.91]\n",
      "  Global_reactive_power: [0.09, 1.35]\n",
      "  Voltage: [224.35, 248.60]\n",
      "  Global_intensity: [9.03, 47.12]\n",
      "  Sub_metering_1: [9.98, 69.44]\n",
      "  Sub_metering_2: [4.54, 78.60]\n",
      "  Sub_metering_3: [2.71, 24.75]\n",
      "\n",
      "Final LAQP estimate: 562522.29\n"
     ]
    }
   ],
   "source": [
    "def laqp_estimate_with_details(query):\n",
    "    # Flatten and predict error (same as before)\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler_div.transform(vec)\n",
    "    pred_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Find the most error-similar historical query\n",
    "    best_index = -1\n",
    "    best_error_diff = float('inf')\n",
    "    best_entry = None\n",
    "\n",
    "    for idx, entry in enumerate(training_data_query_log):\n",
    "        error_diff = abs(entry['error'] - pred_error)\n",
    "        if error_diff < best_error_diff:\n",
    "            best_error_diff = error_diff\n",
    "            best_index = idx\n",
    "            best_entry = entry\n",
    "    \n",
    "    # Compute estimates\n",
    "    sample_new = sample_sum(agg_col, query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    final_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    \n",
    "    print(f\"Selected optimal query index: {best_index} (out of  {len(training_data_query_log)})\")\n",
    "    print(f\"Predicted error for new query: {pred_error:.2f}\")\n",
    "    print(f\"Chosen historical query error: {best_entry['error']:.2f} (diff: {best_error_diff:.2f})\")\n",
    "    # print(\"Predicate ranges of chosen query:\")\n",
    "    # for dim, (l, u) in best_entry['query'].items():\n",
    "    #     print(f\"  {dim}: [{l:.2f}, {u:.2f}]\")\n",
    "    # print(f\"\\nFinal LAQP estimate: {final_est:.2f}\")    \n",
    "\n",
    "    return final_est, best_index, best_entry\n",
    "\n",
    "# Use it\n",
    "estimate, opt_idx, opt_entry = laqp_estimate_with_details(new_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f582b3",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate and Extend\n",
    "Basic Evaluation: Measure Accuracy on Test Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19c042",
   "metadata": {},
   "source": [
    "Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8c7c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def range_distance(q1, q2):\n",
    "    \"\"\"Euclidean distance on flattened predicate bounds (for range-similarity).\"\"\"\n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "    for dim in dimensions:\n",
    "        l1, u1 = q1[dim]\n",
    "        l2, u2 = q2[dim]\n",
    "        vec1.extend([l1, u1])\n",
    "        vec2.extend([l2, u2])\n",
    "    return np.linalg.norm(np.array(vec1) - np.array(vec2))\n",
    "\n",
    "def optimize_alpha(val_queries, model, sample, full_data_size, bounds=(0,1)):\n",
    "    \"\"\"\n",
    "    Tune alpha for hybrid similarity (paper Section 5.3).\n",
    "    val_queries: List of {'query': dict, 'exact': float} for tuning.\n",
    "    Returns best alpha that minimizes average relative error on val set.\n",
    "    \"\"\"\n",
    "    def objective(alpha):\n",
    "        errors = []\n",
    "        for vq in val_queries:\n",
    "            query = vq['query']\n",
    "            exact = vq['exact']\n",
    "            \n",
    "            # Predict error\n",
    "            vec = [query[dim][i] for dim in dimensions for i in range(2)]\n",
    "            vec = np.array([vec])\n",
    "            scaled = scaler_div.transform(vec)\n",
    "            pred_error = model.predict(scaled)[0]\n",
    "            \n",
    "            # Find best entry with hybrid similarity\n",
    "            best_entry = min(training_data_query_log, key=lambda e: \n",
    "                alpha * abs(e['error'] - pred_error) + \n",
    "                (1 - alpha) * range_distance(query, e['query']))\n",
    "            \n",
    "            # LAQP estimate\n",
    "            sample_new = sample_sum(agg_col, query, sample, full_data_size)\n",
    "            sample_opt = best_entry['estimate']\n",
    "            laqp_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "            \n",
    "            # Relative error\n",
    "            rel_err = abs(laqp_est - exact) / (exact + 1e-6)\n",
    "            errors.append(rel_err)\n",
    "        \n",
    "        return np.mean(errors)\n",
    "    \n",
    "    # Optimize alpha\n",
    "    res = minimize_scalar(objective, bounds=bounds, method='bounded')\n",
    "    best_alpha = res.x\n",
    "    print(f\"Optimized alpha: {best_alpha:.3f} (MSE on val: {res.fun:.4f})\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dbe9879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized alpha: 1.000 (MSE on val: 0.1138)\n",
      "Using minimum exact threshold: 1000.00 (avg exact = 11373.18)\n"
     ]
    }
   ],
   "source": [
    "best_alpha = optimize_alpha(testing_data_query_log, model, sample, full_data_size)\n",
    "\n",
    "# Evaluation lists\n",
    "laqp_rel_errors = []\n",
    "sampling_rel_errors = []\n",
    "laqp_abs_errors = []\n",
    "sampling_abs_errors = []\n",
    "\n",
    "# Threshold for filtering tiny queries (adjustable)\n",
    "# Good starting values: 1000 or 0.01 * average exact sum\n",
    "avg_exact = np.mean([tq['exact'] for tq in testing_data_query_log])\n",
    "min_exact_threshold = max(1000.0, 0.01 * avg_exact)  # at least 1000 or 1% of avg\n",
    "\n",
    "print(f\"Using minimum exact threshold: {min_exact_threshold:.2f} \"\n",
    "      f\"(avg exact = {avg_exact:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b10c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Evaluated on 100 / 100 queries (excluded 0 tiny ones)\n",
      "\n",
      "LAQP    Average Relative Error (ARE): 0.1138\n",
      "LAQP    Median Relative Error:       0.0899\n",
      "LAQP    Mean Absolute Error (MAE):     1424.70\n",
      "\n",
      "Sampling ARE:                       0.6570\n",
      "Sampling Median Relative Error:     0.5882\n",
      "Sampling MAE:                       6035.07\n",
      "\n",
      "Improvement (Sampling ARE / LAQP ARE): 5.78x\n"
     ]
    }
   ],
   "source": [
    "filtered_count = 0\n",
    "\n",
    "for tq in testing_data_query_log:\n",
    "    query = tq['query']\n",
    "    exact = tq['exact']\n",
    "    \n",
    "    if exact < min_exact_threshold:\n",
    "        continue  # skip tiny queries that distort relative error\n",
    "    filtered_count += 1\n",
    "    \n",
    "    # --- Pure Sampling Estimate ---\n",
    "    sample_est = sample_sum(agg_col, query, sample, full_data_size)\n",
    "    sampling_abs = abs(sample_est - exact)\n",
    "    sampling_rel = sampling_abs / exact\n",
    "    \n",
    "    sampling_abs_errors.append(sampling_abs)\n",
    "    sampling_rel_errors.append(sampling_rel)\n",
    "    \n",
    "    # --- LAQP Estimate ---\n",
    "    # Flatten and predict error\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler_div.transform(vec)\n",
    "    predicted_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Hybrid selection\n",
    "    best_entry = min(training_data_query_log, key=lambda e: \n",
    "        best_alpha * abs(e['error'] - predicted_error) + \n",
    "        (1 - best_alpha) * range_distance(query, e['query']))\n",
    "    \n",
    "    # Compute estimates\n",
    "    sample_new = sample_sum(agg_col, query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    laqp_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    \n",
    "    laqp_abs = abs(laqp_est - exact)\n",
    "    laqp_rel = laqp_abs / exact\n",
    "    \n",
    "    laqp_abs_errors.append(laqp_abs)\n",
    "    laqp_rel_errors.append(laqp_rel)\n",
    "\n",
    "# Results\n",
    "print(f\"Evaluated on {filtered_count} / {len(testing_data_query_log)} queries \"\n",
    "      f\"(excluded {len(testing_data_query_log)-filtered_count} tiny ones)\")\n",
    "\n",
    "if len(laqp_rel_errors) > 0:\n",
    "    print(f\"\\nLAQP    Average Relative Error (ARE): {np.mean(laqp_rel_errors):.4f}\")\n",
    "    print(f\"LAQP    Median Relative Error:       {np.median(laqp_rel_errors):.4f}\")\n",
    "    print(f\"LAQP    Mean Absolute Error (MAE):     {np.mean(laqp_abs_errors):.2f}\")\n",
    "    \n",
    "    print(f\"\\nSampling ARE:                       {np.mean(sampling_rel_errors):.4f}\")\n",
    "    print(f\"Sampling Median Relative Error:     {np.median(sampling_rel_errors):.4f}\")\n",
    "    print(f\"Sampling MAE:                       {np.mean(sampling_abs_errors):.2f}\")\n",
    "    \n",
    "    improvement = np.mean(sampling_rel_errors) / np.mean(laqp_rel_errors)\n",
    "    print(f\"\\nImprovement (Sampling ARE / LAQP ARE): {improvement:.2f}x\")\n",
    "else:\n",
    "    print(\"No queries passed the threshold — try lowering min_exact_threshold\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
