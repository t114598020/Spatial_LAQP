{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17bae3c",
   "metadata": {},
   "source": [
    "### Step1: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 2049280 rows\n",
      "First 5 data:    timestamp  Global_active_power  Global_reactive_power  Voltage  \\\n",
      "0        0.0                4.216                  0.418   234.84   \n",
      "1       60.0                5.360                  0.436   233.63   \n",
      "2      120.0                5.374                  0.498   233.29   \n",
      "3      180.0                5.388                  0.502   233.74   \n",
      "4      240.0                3.666                  0.528   235.68   \n",
      "\n",
      "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "0              18.4             0.0             1.0            17.0  \n",
      "1              23.0             0.0             1.0            16.0  \n",
      "2              23.0             0.0             2.0            17.0  \n",
      "3              23.0             0.0             1.0            17.0  \n",
      "4              15.8             0.0             1.0            17.0  \n",
      "Data size: 2049280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to extracted TXT file\n",
    "file_path = 'household_power_consumption.txt'\n",
    "\n",
    "# Load with ; separator, handle '?' as NaN\n",
    "data = pd.read_csv(file_path, sep=';', na_values='?')\n",
    "\n",
    "# Combine Date and Time to datetime\n",
    "data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Numerical timestamp: seconds since the earliest date\n",
    "min_dt = data['datetime'].min()\n",
    "data['timestamp'] = (data['datetime'] - min_dt).dt.total_seconds()\n",
    "\n",
    "# Relevant columns (drop Date/Time/datetime, keep numerics)\n",
    "cols = ['timestamp', 'Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "        'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "data = data[cols].dropna()  # ~1.25% missing, drop for simplicity\n",
    "full_data_size = len(data)\n",
    "\n",
    "print(f\"Dataset loaded: {data.shape[0]} rows\")\n",
    "print(f\"First 5 data: {data.head()}\")\n",
    "print(f\"Data size: {full_data_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad053a51",
   "metadata": {},
   "source": [
    "### Step2: Create a Small Offline Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56d105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample created: 2049 rows\n",
      "          timestamp  Global_active_power  Global_reactive_power  Voltage  \\\n",
      "1030580  61834800.0                1.502                  0.074   240.17   \n",
      "1815       108900.0                0.374                  0.264   245.50   \n",
      "1295977  77758620.0                0.620                  0.300   239.85   \n",
      "206669   12400140.0                0.280                  0.200   235.72   \n",
      "1048893  62933580.0                1.372                  0.054   243.95   \n",
      "\n",
      "         Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
      "1030580               6.4             0.0             0.0            18.0  \n",
      "1815                  1.8             0.0             2.0             0.0  \n",
      "1295977               3.0             0.0             1.0             1.0  \n",
      "206669                1.4             0.0             0.0             0.0  \n",
      "1048893               5.6             0.0             0.0            18.0  \n"
     ]
    }
   ],
   "source": [
    "sample_size = int(0.001 * len(data))  # ~2000 rows\n",
    "sample = data.sample(n=sample_size, random_state=42).copy()\n",
    "print(f\"Sample created: {sample.shape[0]} rows\")\n",
    "print(sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b378af9",
   "metadata": {},
   "source": [
    "### Step 3: Generate a Historical Query Log\n",
    "直接抓query因為dimension很大的問題，result有可能會是0，因此先將範圍大概縮在中間50%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07963f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim: timestamp, min value: 0.0, max value: 124515480.0\n",
      "dim: Global_reactive_power, min value: 0.0, max value: 1.39\n",
      "dim: Voltage, min value: 223.2, max value: 254.15\n",
      "dim: Global_intensity, min value: 0.2, max value: 48.4\n",
      "dim: Sub_metering_1, min value: 0.0, max value: 88.0\n",
      "dim: Sub_metering_2, min value: 0.0, max value: 80.0\n",
      "dim: Sub_metering_3, min value: 0.0, max value: 31.0\n",
      "{'timestamp': (2594830.0139828413, 115491449.07118052), 'Global_reactive_power': (0.23966607177486599, 1.1370852710695831), 'Voltage': (225.12716189494918, 247.86576800729415), 'Global_intensity': (4.96397750296437, 36.96420798178017), 'Sub_metering_1': (14.096431920137086, 85.49236232258518), 'Sub_metering_2': (5.486723722658424, 66.84763094086101), 'Sub_metering_3': (3.374133516707752, 25.790545769926748)}\n"
     ]
    }
   ],
   "source": [
    "from funcs import generate_random_query, exact_sum, sample_sum\n",
    "\n",
    "# Define dimensions (7D) and their min/max\n",
    "dimensions = ['timestamp', 'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "              'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "q = generate_random_query(data, dimensions, test = True)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98367360",
   "metadata": {},
   "source": [
    "Functions for exact sum, sample sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e275d",
   "metadata": {},
   "source": [
    "建立query log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3f0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate avg_exact by temp queries...\n",
      "Generated 2000 temp queries in 2000 attempts\n",
      "Average exact sum: avg_exact=10230.512895\n",
      "Generating 2000 queries...\n",
      "Generated 2000 queries in 4000 attempts\n"
     ]
    }
   ],
   "source": [
    "# Aggregate column\n",
    "agg_col = 'Global_active_power'\n",
    "\n",
    "# 設定一個avg exact讓threshold有依據\n",
    "print(\"Generate avg_exact by temp queries...\")\n",
    "temp_query_log = []\n",
    "num_queries = 2000\n",
    "attempts = 0\n",
    "max_attempts = 10000\n",
    "\n",
    "while len(temp_query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    if exact_result > 1.0:  # 會有result為0的情況，設定threshold\n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        temp_query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "avg_exact = np.mean([temp_query['exact'] for temp_query in temp_query_log])\n",
    "print(f\"Generated {len(temp_query_log)} temp queries in {attempts} attempts\")\n",
    "print(f\"Average exact sum: {avg_exact=}\")\n",
    "\n",
    "# For training: 2000 queries (as in paper)\n",
    "query_log = []\n",
    "print(\"Generating 2000 queries...\")\n",
    "while len(query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    \n",
    "    if exact_result > 0.01 * avg_exact: \n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "print(f\"Generated {len(query_log)} queries in {attempts} attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b5c4e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (317889.14719108393, 95484735.34709866),\n",
       "  'Global_reactive_power': (0.08176741717106216, 1.2001717279694588),\n",
       "  'Voltage': (224.99723593786194, 253.5116929519517),\n",
       "  'Global_intensity': (10.255683845754504, 45.795909137749476),\n",
       "  'Sub_metering_1': (11.41996008670598, 68.08800969980449),\n",
       "  'Sub_metering_2': (0.613595062827188, 69.98365714218588),\n",
       "  'Sub_metering_3': (3.5054635130669345, 27.912309334612747)},\n",
       " 'exact': 42442.814000000006,\n",
       " 'estimate': 38571.270122010734,\n",
       " 'error': 3871.543877989272}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_log[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e79b0",
   "metadata": {},
   "source": [
    "### Step 4: Compute Sampling-Based Estimates and Errors for the Query Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745dc2d",
   "metadata": {},
   "source": [
    "Diversification: training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversified query log: selected 1000 / 2000 entries\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "scaler_div = StandardScaler()\n",
    "\n",
    "def diversify_query_log(query_log, k):\n",
    "    \"\"\"\n",
    "    Diversify the query log using greedy max-min (paper Section 5.2).\n",
    "    Features: flattened ranges + error.\n",
    "    Returns a subset of k diverse entries.\n",
    "    \"\"\"\n",
    "    # Prepare features: flatten query bounds + error\n",
    "    features = []\n",
    "    for entry in query_log:\n",
    "        vec = []\n",
    "        for dim in dimensions:\n",
    "            lower, upper = entry['query'][dim]\n",
    "            vec.extend([lower, upper])\n",
    "        vec.append(entry['error'])\n",
    "        features.append(vec)\n",
    "    \n",
    "    features = np.array(features)\n",
    "    features_norm = scaler_div.fit_transform(features)\n",
    "    \n",
    "    # Greedy max-min selection\n",
    "    selected_indices = [random.randint(0, len(features)-1)]  # Start with random\n",
    "    selected_features = features_norm[selected_indices]\n",
    "    \n",
    "    while len(selected_indices) < k:\n",
    "        # Distances from unselected to current selected set\n",
    "        dists = euclidean_distances(selected_features, features_norm)\n",
    "        min_dists = dists.min(axis=0)  # Min dist to any selected\n",
    "        # Pick the one with max min-dist (most diverse)\n",
    "        next_idx = np.argmax(min_dists)\n",
    "        selected_indices.append(next_idx)\n",
    "        selected_features = features_norm[selected_indices]\n",
    "    \n",
    "    diversified_log = [query_log[i] for i in selected_indices]\n",
    "    print(f\"Diversified query log: selected {len(diversified_log)} / {len(query_log)} entries\")\n",
    "    return diversified_log\n",
    "\n",
    "diversified_log = diversify_query_log(query_log, k=800) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8bd80",
   "metadata": {},
   "source": [
    "Generate testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generate testing...\")\n",
    "temp_query_log = []\n",
    "num_queries = 100\n",
    "attempts = 0\n",
    "max_attempts = 1000\n",
    "\n",
    "while len(temp_query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(agg_col, q, data)\n",
    "    if exact_result > 0.01 * avg_exact:  # 會有result為0的情況，設定threshold\n",
    "        estimate = sample_sum(agg_col, q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        temp_query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "avg_exact = np.mean([temp_query['exact'] for temp_query in temp_query_log])\n",
    "print(f\"Generated {len(temp_query_log)} testing data in {attempts} attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6db18d",
   "metadata": {},
   "source": [
    "Load data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb06da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 讀取資料\n",
    "# with open('diversify_log.pkl', 'rb') as f:\n",
    "#     diversified_log = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac190cef",
   "metadata": {},
   "source": [
    "### Step 5: Train the Error Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4500066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features (flatten: lower/upper per dim) and targets (errors)\n",
    "X = []\n",
    "y = []\n",
    "# for entry in query_log:\n",
    "for entry in diversified_log:\n",
    "\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        lower, upper = entry['query'][dim]\n",
    "        vec.extend([lower, upper])\n",
    "    X.append(vec)\n",
    "    y.append(entry['error'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize\n",
    "X_scaled = scaler_div.fit_transform(X)\n",
    "\n",
    "# Train (80/20 split for validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "# adjust max_depth\n",
    "model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model trained.\")\n",
    "# print(f\"Test MSE: {np.mean((model.predict(X_test) - y_test)**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed20f77",
   "metadata": {},
   "source": [
    "### Step 6: Estimate a New Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeb865d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAQP estimate: 555401.61\n",
      "Exact sum: 560494.03\n",
      "Relative error: 0.0091\n"
     ]
    }
   ],
   "source": [
    "# Example new 7D query (adjust ranges to sensible values based on data mins/maxes)\n",
    "new_query = {\n",
    "    'timestamp': (0, 1e8),  # e.g., first ~few months in seconds\n",
    "    'Global_reactive_power': (0.0, 0.5),\n",
    "    'Voltage': (220, 250),\n",
    "    'Global_intensity': (0, 20),\n",
    "    'Sub_metering_1': (0, 10),\n",
    "    'Sub_metering_2': (0, 5),\n",
    "    'Sub_metering_3': (0, 15)\n",
    "}\n",
    "\n",
    "# Flatten and scale\n",
    "new_vec = []\n",
    "for dim in dimensions:\n",
    "    lower, upper = new_query[dim]\n",
    "    new_vec.extend([lower, upper])\n",
    "new_vec = np.array([new_vec])\n",
    "new_scaled = scaler_div.transform(new_vec)\n",
    "\n",
    "# Predict error\n",
    "predicted_error = model.predict(new_scaled)[0]\n",
    "\n",
    "# Find error-similar historical query (closest error)\n",
    "min_diff = float('inf')\n",
    "opt_entry = None\n",
    "for entry in diversified_log:\n",
    "    error_diff = abs(entry['error'] - predicted_error)\n",
    "    if error_diff < min_diff:\n",
    "        min_diff = error_diff\n",
    "        opt_entry = entry\n",
    "\n",
    "# Compute final estimate\n",
    "sample_new = sample_sum(new_query, sample, full_data_size)\n",
    "sample_opt = opt_entry['estimate']\n",
    "final_estimate = opt_entry['exact'] + (sample_new - sample_opt)\n",
    "\n",
    "print(f\"LAQP estimate: {final_estimate:.2f}\")\n",
    "# Compute exact for the same query (for debugging/small queries)\n",
    "exact = exact_sum(new_query, data)\n",
    "print(f\"Exact sum: {exact:.2f}\")\n",
    "print(f\"Relative error: {abs(final_estimate - exact) / exact:.4f}\")\n",
    "\n",
    "# Also see how many rows match\n",
    "# mask = np.ones(len(data), dtype=bool)\n",
    "# for dim, (l, u) in new_query.items():\n",
    "#     mask &= (data[dim] >= l) & (data[dim] <= u)\n",
    "# matched_rows = mask.sum()\n",
    "# print(f\"Query matches {matched_rows:,} rows ({matched_rows / len(data):.1%} of dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a3a02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laqp_estimate_with_details(query):\n",
    "    # Flatten and predict error (same as before)\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler_div.transform(vec)\n",
    "    pred_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Find the most error-similar historical query\n",
    "    best_index = -1\n",
    "    best_error_diff = float('inf')\n",
    "    best_entry = None\n",
    "\n",
    "    for idx, entry in enumerate(diversified_log):\n",
    "        error_diff = abs(entry['error'] - pred_error)\n",
    "        if error_diff < best_error_diff:\n",
    "            best_error_diff = error_diff\n",
    "            best_index = idx\n",
    "            best_entry = entry\n",
    "    \n",
    "    # Compute estimates\n",
    "    sample_new = sample_sum(query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    final_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    \n",
    "    print(f\"Selected optimal query index: {best_index} (out of  {len(diversified_log)})\")\n",
    "    print(f\"Predicted error for new query: {pred_error:.2f}\")\n",
    "    print(f\"Chosen historical query error: {best_entry['error']:.2f} (diff: {best_error_diff:.2f})\")\n",
    "    print(f\"Exact result of chosen query: {best_entry['exact']:.2f}\")\n",
    "    print(\"Predicate ranges of chosen query:\")\n",
    "    for dim, (l, u) in best_entry['query'].items():\n",
    "        print(f\"  {dim}: [{l:.2f}, {u:.2f}]\")\n",
    "    print(f\"\\nFinal LAQP estimate: {final_est:.2f}\")    \n",
    "\n",
    "    return final_est, best_index, best_entry\n",
    "\n",
    "# Use it\n",
    "# estimate, opt_idx, opt_entry = laqp_estimate_with_details(new_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f582b3",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate and Extend\n",
    "Basic Evaluation: Measure Accuracy on Test Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19c042",
   "metadata": {},
   "source": [
    "Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a716d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_distance(q1, q2):\n",
    "    \"\"\"Euclidean distance on flattened predicate bounds (for range-similarity).\"\"\"\n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "    for dim in dimensions:\n",
    "        l1, u1 = q1[dim]\n",
    "        l2, u2 = q2[dim]\n",
    "        vec1.extend([l1, u1])\n",
    "        vec2.extend([l2, u2])\n",
    "    return np.linalg.norm(np.array(vec1) - np.array(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8c7c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def optimize_alpha(val_queries, model, sample, full_data_size, bounds=(0,1)):\n",
    "    \"\"\"\n",
    "    Tune alpha for hybrid similarity (paper Section 5.3).\n",
    "    val_queries: List of {'query': dict, 'exact': float} for tuning.\n",
    "    Returns best alpha that minimizes average relative error on val set.\n",
    "    \"\"\"\n",
    "    def objective(alpha):\n",
    "        errors = []\n",
    "        for vq in val_queries:\n",
    "            query = vq['query']\n",
    "            exact = vq['exact']\n",
    "            \n",
    "            # Predict error\n",
    "            vec = [query[dim][i] for dim in dimensions for i in range(2)]\n",
    "            vec = np.array([vec])\n",
    "            scaled = scaler_div.transform(vec)\n",
    "            pred_error = model.predict(scaled)[0]\n",
    "            \n",
    "            # Find best entry with hybrid similarity\n",
    "            best_entry = min(diversified_log, key=lambda e: \n",
    "                alpha * abs(e['error'] - pred_error) + \n",
    "                (1 - alpha) * range_distance(query, e['query']))\n",
    "            \n",
    "            # LAQP estimate\n",
    "            sample_new = sample_sum(query, sample, full_data_size)\n",
    "            sample_opt = best_entry['estimate']\n",
    "            laqp_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "            \n",
    "            # Relative error\n",
    "            rel_err = abs(laqp_est - exact) / (exact + 1e-6)\n",
    "            errors.append(rel_err)\n",
    "        \n",
    "        return np.mean(errors)\n",
    "    \n",
    "    # Optimize alpha\n",
    "    res = minimize_scalar(objective, bounds=bounds, method='bounded')\n",
    "    best_alpha = res.x\n",
    "    print(f\"Optimized alpha: {best_alpha:.3f} (MSE on val: {res.fun:.4f})\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe9879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 test queries...\n",
      "Generated 100 test queries\n",
      "Optimized alpha: 0.618 (MSE on val: 0.5282)\n",
      "Using minimum exact threshold: 1000.00 (avg exact = 10006.51)\n"
     ]
    }
   ],
   "source": [
    "# Generate 100 separate test queries\n",
    "test_queries = []\n",
    "num_test = 100\n",
    "attempts = 0\n",
    "max_attempts = 1000\n",
    "\n",
    "print(\"Generating 100 test queries...\")\n",
    "while len(test_queries) < num_test and attempts < max_attempts:\n",
    "    q = generate_random_query(data, dimensions)\n",
    "    exact_result = exact_sum(q, data)\n",
    "    if exact_result > 0.01 * avg_exact:\n",
    "        test_queries.append({'query': q, 'exact': exact_result})\n",
    "\n",
    "print(f\"Generated {len(test_queries)} test queries\")\n",
    "\n",
    "best_alpha = optimize_alpha(test_queries, model, sample, full_data_size)\n",
    "\n",
    "# Evaluation lists\n",
    "laqp_rel_errors = []\n",
    "sampling_rel_errors = []\n",
    "laqp_abs_errors = []\n",
    "sampling_abs_errors = []\n",
    "\n",
    "# Threshold for filtering tiny queries (adjustable)\n",
    "# Good starting values: 1000 or 0.01 * average exact sum\n",
    "avg_exact = np.mean([tq['exact'] for tq in test_queries])\n",
    "min_exact_threshold = max(1000.0, 0.01 * avg_exact)  # at least 1000 or 1% of avg\n",
    "\n",
    "print(f\"Using minimum exact threshold: {min_exact_threshold:.2f} \"\n",
    "      f\"(avg exact = {avg_exact:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b10c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Evaluated on 100 / 100 queries (excluded 0 tiny ones)\n",
      "\n",
      "LAQP    Average Relative Error (ARE): 0.5282\n",
      "LAQP    Median Relative Error:       0.3287\n",
      "LAQP    Mean Absolute Error (MAE):     4319.04\n",
      "\n",
      "Sampling ARE:                       0.6656\n",
      "Sampling Median Relative Error:     0.6502\n",
      "Sampling MAE:                       5472.43\n",
      "\n",
      "Improvement (Sampling ARE / LAQP ARE): 1.26x\n"
     ]
    }
   ],
   "source": [
    "filtered_count = 0\n",
    "\n",
    "for tq in test_queries:\n",
    "    query = tq['query']\n",
    "    exact = tq['exact']\n",
    "    \n",
    "    if exact < min_exact_threshold:\n",
    "        continue  # skip tiny queries that distort relative error\n",
    "    filtered_count += 1\n",
    "    \n",
    "    # --- Pure Sampling Estimate ---\n",
    "    sample_est = sample_sum(query, sample, full_data_size)\n",
    "    sampling_abs = abs(sample_est - exact)\n",
    "    sampling_rel = sampling_abs / exact\n",
    "    \n",
    "    sampling_abs_errors.append(sampling_abs)\n",
    "    sampling_rel_errors.append(sampling_rel)\n",
    "    \n",
    "    # --- LAQP Estimate ---\n",
    "    # Flatten and predict error\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler_div.transform(vec)\n",
    "    predicted_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Hybrid selection\n",
    "    best_entry = min(diversified_log, key=lambda e: \n",
    "        best_alpha * abs(e['error'] - predicted_error) + \n",
    "        (1 - best_alpha) * range_distance(query, e['query']))\n",
    "    \n",
    "    # Compute estimates\n",
    "    sample_new = sample_sum(query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    laqp_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    \n",
    "    laqp_abs = abs(laqp_est - exact)\n",
    "    laqp_rel = laqp_abs / exact\n",
    "    \n",
    "    laqp_abs_errors.append(laqp_abs)\n",
    "    laqp_rel_errors.append(laqp_rel)\n",
    "\n",
    "# ========================\n",
    "# Results\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Evaluated on {filtered_count} / {len(test_queries)} queries \"\n",
    "      f\"(excluded {len(test_queries)-filtered_count} tiny ones)\")\n",
    "\n",
    "if len(laqp_rel_errors) > 0:\n",
    "    print(f\"\\nLAQP    Average Relative Error (ARE): {np.mean(laqp_rel_errors):.4f}\")\n",
    "    print(f\"LAQP    Median Relative Error:       {np.median(laqp_rel_errors):.4f}\")\n",
    "    print(f\"LAQP    Mean Absolute Error (MAE):     {np.mean(laqp_abs_errors):.2f}\")\n",
    "    \n",
    "    print(f\"\\nSampling ARE:                       {np.mean(sampling_rel_errors):.4f}\")\n",
    "    print(f\"Sampling Median Relative Error:     {np.median(sampling_rel_errors):.4f}\")\n",
    "    print(f\"Sampling MAE:                       {np.mean(sampling_abs_errors):.2f}\")\n",
    "    \n",
    "    improvement = np.mean(sampling_rel_errors) / np.mean(laqp_rel_errors)\n",
    "    print(f\"\\nImprovement (Sampling ARE / LAQP ARE): {improvement:.2f}x\")\n",
    "else:\n",
    "    print(\"No queries passed the threshold — try lowering min_exact_threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e2668",
   "metadata": {},
   "source": [
    "### Store data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 儲存資料 (原本的 data_list)\n",
    "with open('data_storage.pkl', 'wb') as f:\n",
    "    pickle.dump(diversified_log, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
