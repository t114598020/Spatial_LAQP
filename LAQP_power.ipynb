{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17bae3c",
   "metadata": {},
   "source": [
    "Step1: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d4d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 2049280 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to extracted TXT file\n",
    "file_path = 'household_power_consumption.txt'\n",
    "\n",
    "# Load with ; separator, handle '?' as NaN\n",
    "data = pd.read_csv(file_path, sep=';', na_values='?')\n",
    "\n",
    "# Combine Date and Time to datetime\n",
    "data['datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Numerical timestamp: seconds since the earliest date\n",
    "min_dt = data['datetime'].min()\n",
    "data['timestamp'] = (data['datetime'] - min_dt).dt.total_seconds()\n",
    "\n",
    "# Relevant columns (drop Date/Time/datetime, keep numerics)\n",
    "cols = ['timestamp', 'Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "        'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "data = data[cols].dropna()  # ~1.25% missing, drop for simplicity\n",
    "\n",
    "print(f\"Dataset loaded: {data.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51fdbbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.0</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.0</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.0</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  Global_active_power  Global_reactive_power  Voltage  \\\n",
       "0        0.0                4.216                  0.418   234.84   \n",
       "1       60.0                5.360                  0.436   233.63   \n",
       "2      120.0                5.374                  0.498   233.29   \n",
       "3      180.0                5.388                  0.502   233.74   \n",
       "4      240.0                3.666                  0.528   235.68   \n",
       "\n",
       "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0              18.4             0.0             1.0            17.0  \n",
       "1              23.0             0.0             1.0            16.0  \n",
       "2              23.0             0.0             2.0            17.0  \n",
       "3              23.0             0.0             1.0            17.0  \n",
       "4              15.8             0.0             1.0            17.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad053a51",
   "metadata": {},
   "source": [
    "Step2: Generate a Historical Query Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a3f0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Generated 2000 valid queries in 2254 attempts (88.7% success rate)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define dimensions (7D) and their min/max\n",
    "dimensions = ['timestamp', 'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "              'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "dim_ranges = {dim: (data[dim].min(), data[dim].max()) for dim in dimensions}\n",
    "\n",
    "# Aggregate column\n",
    "agg_col = 'Global_active_power'\n",
    "\n",
    "# Add this after loading data\n",
    "quantiles_low = data[dimensions].quantile(0.05)\n",
    "quantiles_high = data[dimensions].quantile(0.95)\n",
    "\n",
    "def generate_random_query_from_rows():\n",
    "    # Sample a random row to anchor the query\n",
    "    row = data.sample(1).iloc[0]\n",
    "    predicates = {}\n",
    "    for dim in dimensions:\n",
    "        value = row[dim]\n",
    "        low_min, low_max = quantiles_low[dim], quantiles_high[dim]\n",
    "        # Choose a random width fraction (adjust 0.1-1.0 for larger ranges; higher = more points)\n",
    "        width_fraction = random.uniform(0.1, 1.0)\n",
    "        delta = width_fraction * (low_max - low_min) / 2\n",
    "        lower = max(low_min, value - delta)\n",
    "        upper = min(low_max, value + delta)\n",
    "        predicates[dim] = (lower, upper)\n",
    "    return predicates\n",
    "\n",
    "# Function to compute exact SUM for a query\n",
    "def exact_sum(query, df):\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for dim, (lower, upper) in query.items():\n",
    "        mask &= (df[dim] >= lower) & (df[dim] <= upper)\n",
    "    return df.loc[mask, agg_col].sum()\n",
    "\n",
    "# Generate query log (e.g., 2000 for training; adjust based on RAM/time)\n",
    "# After data loading and quantile computation\n",
    "query_log = []\n",
    "num_queries = 2000\n",
    "attempts = 0\n",
    "max_attempts = 20000\n",
    "\n",
    "while len(query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query_from_rows()  # or _from_rows()\n",
    "    exact_result = exact_sum(q, data)\n",
    "    \n",
    "    if exact_result > 0.01:  # small threshold to avoid floating-point zero\n",
    "        estimate = sample_sum(q, sample, full_data_size)\n",
    "        error = exact_result - estimate\n",
    "        query_log.append({'query': q, 'exact': exact_result, \n",
    "                          'estimate': estimate, 'error': error})\n",
    "    attempts += 1\n",
    "\n",
    "print(f\"Success! Generated {len(query_log)} valid queries in {attempts} attempts \"\n",
    "      f\"({len(query_log)/attempts:.1%} success rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b867c8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (87824794.90096335, 102635965.09903665),\n",
       "  'Global_reactive_power': (0.0, 0.13174039815164684),\n",
       "  'Voltage': (243.0695629408365, 245.94),\n",
       "  'Global_intensity': (0.8, 10.915215075500232),\n",
       "  'Sub_metering_1': (0.0, 0.18648809148156936),\n",
       "  'Sub_metering_2': (0.0, 0.7490313873441946),\n",
       "  'Sub_metering_3': (13.707605818536464, 19.0)},\n",
       " 'exact': 17540.63,\n",
       " 'estimate': 19190.622079062956,\n",
       " 'error': -1649.9920790629549}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_log[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28dac7",
   "metadata": {},
   "source": [
    "Step 3: Create a Small Offline Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0caaa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample created: 2049 rows\n"
     ]
    }
   ],
   "source": [
    "sample_size = int(0.001 * len(data))  # ~2000 rows\n",
    "sample = data.sample(n=sample_size, random_state=42).copy()\n",
    "print(f\"Sample created: {sample.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e79b0",
   "metadata": {},
   "source": [
    "Step 4: Compute Sampling-Based Estimates and Errors for the Query Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552d1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates and errors computed for query log\n"
     ]
    }
   ],
   "source": [
    "# Function for sampling-based approximate SUM (scaled)\n",
    "def sample_sum(query, samp_df, full_size):\n",
    "    mask = np.ones(len(samp_df), dtype=bool)\n",
    "    for dim, (lower, upper) in query.items():\n",
    "        mask &= (samp_df[dim] >= lower) & (samp_df[dim] <= upper)\n",
    "    subset_sum = samp_df.loc[mask, agg_col].sum()\n",
    "    scale = full_size / len(samp_df)\n",
    "    return subset_sum * scale\n",
    "\n",
    "# Add estimates and errors to query log\n",
    "full_data_size = len(data)\n",
    "for entry in query_log:\n",
    "    entry['estimate'] = sample_sum(entry['query'], sample, full_data_size)\n",
    "    entry['error'] = entry['exact'] - entry['estimate']\n",
    "\n",
    "print(\"Estimates and errors computed for query log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08cd8c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (84910097.51229969, 118053362.99999999),\n",
       "  'Global_reactive_power': (0.0, 0.2752887970714636),\n",
       "  'Voltage': (240.53501883878465, 244.06498116121537),\n",
       "  'Global_intensity': (1.7706663772775233, 10.229333622722477),\n",
       "  'Sub_metering_1': (0.0, 0.19281273018858813),\n",
       "  'Sub_metering_2': (0.0, 0.3745196392738447),\n",
       "  'Sub_metering_3': (15.234280222606268, 19.0)},\n",
       " 'exact': 63787.716,\n",
       " 'estimate': 62012.47297218155,\n",
       " 'error': 1775.2430278184474}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_log[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac190cef",
   "metadata": {},
   "source": [
    "Step 5: Train the Error Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4500066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained. Test MSE: 12228394.507754307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features (flatten: lower/upper per dim) and targets (errors)\n",
    "X = []\n",
    "y = []\n",
    "for entry in query_log:\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        lower, upper = entry['query'][dim]\n",
    "        vec.extend([lower, upper])\n",
    "    X.append(vec)\n",
    "    y.append(entry['error'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train (80/20 split for validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)  # As in paper\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model trained. Test MSE: {np.mean((model.predict(X_test) - y_test)**2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed20f77",
   "metadata": {},
   "source": [
    "Step 6: Estimate a New Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb865d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final estimate for new query: 550735.0209702294\n"
     ]
    }
   ],
   "source": [
    "# Example new 7D query (adjust ranges to sensible values based on data mins/maxes)\n",
    "new_query = {\n",
    "    'timestamp': (0, 1e8),  # e.g., first ~few months in seconds\n",
    "    'Global_reactive_power': (0.0, 0.5),\n",
    "    'Voltage': (220, 250),\n",
    "    'Global_intensity': (0, 20),\n",
    "    'Sub_metering_1': (0, 10),\n",
    "    'Sub_metering_2': (0, 5),\n",
    "    'Sub_metering_3': (0, 15)\n",
    "}\n",
    "\n",
    "# Flatten and scale\n",
    "new_vec = []\n",
    "for dim in dimensions:\n",
    "    lower, upper = new_query[dim]\n",
    "    new_vec.extend([lower, upper])\n",
    "new_vec = np.array([new_vec])\n",
    "new_scaled = scaler.transform(new_vec)\n",
    "\n",
    "# Predict error\n",
    "predicted_error = model.predict(new_scaled)[0]\n",
    "\n",
    "# Find error-similar historical query (closest error)\n",
    "min_diff = float('inf')\n",
    "opt_entry = None\n",
    "for entry in query_log:\n",
    "    error_diff = abs(entry['error'] - predicted_error)\n",
    "    if error_diff < min_diff:\n",
    "        min_diff = error_diff\n",
    "        opt_entry = entry\n",
    "\n",
    "# Compute final estimate\n",
    "sample_new = sample_sum(new_query, sample, full_data_size)\n",
    "sample_opt = opt_entry['estimate']\n",
    "final_estimate = opt_entry['exact'] + (sample_new - sample_opt)\n",
    "\n",
    "print(f\"Final estimate for new query: {final_estimate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6e22745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAQP estimate: 550735.02\n",
      "Exact sum: 560494.03\n",
      "Relative error: 0.0174\n",
      "Query matches 1,059,647 rows (51.7% of dataset)\n"
     ]
    }
   ],
   "source": [
    "# After computing final_estimate\n",
    "print(f\"LAQP estimate: {final_estimate:.2f}\")\n",
    "\n",
    "# Compute exact for the same query (for debugging/small queries)\n",
    "exact = exact_sum(new_query, data)\n",
    "print(f\"Exact sum: {exact:.2f}\")\n",
    "print(f\"Relative error: {abs(final_estimate - exact) / exact:.4f}\")\n",
    "\n",
    "# Also see how many rows match\n",
    "mask = np.ones(len(data), dtype=bool)\n",
    "for dim, (l, u) in new_query.items():\n",
    "    mask &= (data[dim] >= l) & (data[dim] <= u)\n",
    "matched_rows = mask.sum()\n",
    "print(f\"Query matches {matched_rows:,} rows ({matched_rows / len(data):.1%} of dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bfc1658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': (0, 100000000.0),\n",
       " 'Global_reactive_power': (0.0, 0.5),\n",
       " 'Voltage': (220, 250),\n",
       " 'Global_intensity': (0, 20),\n",
       " 'Sub_metering_1': (0, 10),\n",
       " 'Sub_metering_2': (0, 5),\n",
       " 'Sub_metering_3': (0, 15)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a3a02e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimal query index: 1108 (out of  2000)\n",
      "Predicted error for new query: 1115.54\n",
      "Chosen historical query error: 1119.93 (diff: 4.38)\n",
      "Exact result of chosen query: 5414.51\n",
      "Predicate ranges of chosen query:\n",
      "  timestamp: [87053530.53, 112156789.47]\n",
      "  Global_reactive_power: [0.00, 0.25]\n",
      "  Voltage: [244.77, 245.94]\n",
      "  Global_intensity: [0.80, 3.98]\n",
      "  Sub_metering_1: [0.00, 0.46]\n",
      "  Sub_metering_2: [0.00, 1.00]\n",
      "  Sub_metering_3: [0.00, 8.90]\n",
      "\n",
      "Final LAQP estimate: 550735.02\n"
     ]
    }
   ],
   "source": [
    "def laqp_estimate_with_details(query):\n",
    "    # Flatten and predict error (same as before)\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler.transform(vec)\n",
    "    pred_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Find the most error-similar historical query\n",
    "    best_index = -1\n",
    "    best_error_diff = float('inf')\n",
    "    best_entry = None\n",
    "\n",
    "    for idx, entry in enumerate(query_log):\n",
    "        error_diff = abs(entry['error'] - pred_error)\n",
    "        if error_diff < best_error_diff:\n",
    "            best_error_diff = error_diff\n",
    "            best_index = idx\n",
    "            best_entry = entry\n",
    "    \n",
    "    # Compute estimates\n",
    "    sample_new = sample_sum(query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    final_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    \n",
    "    print(f\"Selected optimal query index: {best_index} (out of  {len(query_log)})\")\n",
    "    print(f\"Predicted error for new query: {pred_error:.2f}\")\n",
    "    print(f\"Chosen historical query error: {best_entry['error']:.2f} (diff: {best_error_diff:.2f})\")\n",
    "    print(f\"Exact result of chosen query: {best_entry['exact']:.2f}\")\n",
    "    print(\"Predicate ranges of chosen query:\")\n",
    "    for dim, (l, u) in best_entry['query'].items():\n",
    "        print(f\"  {dim}: [{l:.2f}, {u:.2f}]\")\n",
    "    print(f\"\\nFinal LAQP estimate: {estimate:.2f}\")    \n",
    "\n",
    "    return final_est, best_index, best_entry\n",
    "\n",
    "# Use it\n",
    "estimate, opt_idx, opt_entry = laqp_estimate_with_details(new_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecc6e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'timestamp': (87053530.53088216, 112156789.46911784),\n",
       "  'Global_reactive_power': (0.0, 0.25219982196670726),\n",
       "  'Voltage': (244.77406960252299, 245.94),\n",
       "  'Global_intensity': (0.8, 3.9761764652470073),\n",
       "  'Sub_metering_1': (0.0, 0.4590564429582048),\n",
       "  'Sub_metering_2': (0.0, 0.9963810778880567),\n",
       "  'Sub_metering_3': (0.0, 8.90128872162247)},\n",
       " 'exact': 5414.512000000001,\n",
       " 'estimate': 4294.586783796974,\n",
       " 'error': 1119.925216203027}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_log[1108]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f582b3",
   "metadata": {},
   "source": [
    "Step 7: Evaluate and Extend\n",
    "Basic Evaluation: Measure Accuracy on Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46b10c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Generated 500 valid queries in 577 attempts (86.7% success rate)\n",
      "Pure Sampling ARE: 0.2529\n",
      "LAQP ARE:          136016837.2035\n",
      "Improvement:       0.00x\n"
     ]
    }
   ],
   "source": [
    "# Generate test queries (e.g., 500 new queries)\n",
    "test_query_log = []\n",
    "num_queries = 500\n",
    "attempts = 0\n",
    "max_attempts = 10000\n",
    "\n",
    "while len(test_query_log) < num_queries and attempts < max_attempts:\n",
    "    q = generate_random_query_from_rows()  # or _from_rows()\n",
    "    exact_result = exact_sum(q, data)\n",
    "    \n",
    "    if exact_result > 0.01:  # small threshold to avoid floating-point zero\n",
    "        test_query_log.append({'query': q, 'exact': exact_result})\n",
    "    attempts += 1\n",
    "print(f\"Success! Generated {len(test_query_log)} valid queries in {attempts} attempts \"\n",
    "      f\"({len(test_query_log)/attempts:.1%} success rate)\")\n",
    "\n",
    "# Compute estimates for each test query\n",
    "laqp_errors = []\n",
    "sampling_errors = []\n",
    "# Optional: aqp_plus_errors = []  # for range-similar baseline\n",
    "\n",
    "for tq in test_queries:\n",
    "    query = tq['query']\n",
    "    exact = tq['exact']\n",
    "    \n",
    "    # 1. Pure sampling estimate\n",
    "    sample_est = sample_sum(query, sample, full_data_size)\n",
    "    sampling_errors.append(abs(sample_est - exact) / (exact + 1e-6))\n",
    "    \n",
    "    # 2. LAQP estimate (reuse the trained model and query_log)\n",
    "    # Flatten and predict error\n",
    "    vec = []\n",
    "    for dim in dimensions:\n",
    "        l, u = query[dim]\n",
    "        vec.extend([l, u])\n",
    "    vec = np.array([vec])\n",
    "    scaled = scaler.transform(vec)\n",
    "    pred_error = model.predict(scaled)[0]\n",
    "    \n",
    "    # Find error-similar historical query\n",
    "    best_entry = min(query_log, key=lambda e: abs(e['error'] - pred_error))\n",
    "    \n",
    "    # LAQP final estimate\n",
    "    sample_new = sample_sum(query, sample, full_data_size)\n",
    "    sample_opt = best_entry['estimate']\n",
    "    laqp_est = best_entry['exact'] + (sample_new - sample_opt)\n",
    "    laqp_errors.append(abs(laqp_est - exact) / (exact + 1e-6))\n",
    "\n",
    "# Results\n",
    "print(f\"Pure Sampling ARE: {np.mean(sampling_errors):.4f}\")\n",
    "print(f\"LAQP ARE:          {np.mean(laqp_errors):.4f}\")\n",
    "print(f\"Improvement:       {np.mean(sampling_errors) / np.mean(laqp_errors):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcc55f",
   "metadata": {},
   "source": [
    "Implement Error Bounds (Confidence Intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ef11729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAQP Estimate: 59793.25 ± 47.99 (95% CI)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def laqp_estimate_with_ci(query, confidence=0.95):\n",
    "    # ... same as above to get best_entry, sample_new, sample_opt ...\n",
    "    \n",
    "    # Compute difference on sample (unscaled for variance)\n",
    "    mask_new = np.ones(len(sample), dtype=bool)\n",
    "    mask_opt = np.ones(len(sample), dtype=bool)\n",
    "    for dim, (l, u) in query.items():\n",
    "        mask_new &= (sample[dim] >= l) & (sample[dim] <= u)\n",
    "    for dim, (l, u) in best_entry['query'].items():\n",
    "        mask_opt &= (sample[dim] >= l) & (sample[dim] <= u)\n",
    "    \n",
    "    values_new = sample.loc[mask_new, agg_col].values\n",
    "    values_opt = sample.loc[mask_opt, agg_col].values\n",
    "    \n",
    "    # Difference per tuple (aligned by padding with 0 if needed - simplified)\n",
    "    # Better: compute variance of (new - opt) contribution\n",
    "    # Simple CLT approximation on scaled difference\n",
    "    diff = sample_new - sample_opt\n",
    "    # Approximate standard error of difference\n",
    "    se_diff = np.sqrt( (np.var(values_new)/len(values_new) if len(values_new)>1 else 0) +\n",
    "                       (np.var(values_opt)/len(values_opt) if len(values_opt)>1 else 0) )\n",
    "    se_diff *= full_data_size / len(sample)  # scale\n",
    "    \n",
    "    z = stats.norm.ppf(1 - (1-confidence)/2)\n",
    "    ci = z * se_diff\n",
    "    \n",
    "    final_est = best_entry['exact'] + diff\n",
    "    return final_est, (final_est - ci, final_est + ci)\n",
    "\n",
    "# Example\n",
    "est, (low, high) = laqp_estimate_with_ci(new_query)\n",
    "print(f\"LAQP Estimate: {est:.2f} ± { (high-low)/2 :.2f} (95% CI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0e8fc",
   "metadata": {},
   "source": [
    "(Later)\n",
    "Extension 1: Diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786878c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def diversify_query_log(entries, k=500):\n",
    "    # Features: flattened ranges + error\n",
    "    features = []\n",
    "    for e in entries:\n",
    "        vec = []\n",
    "        for dim in dimensions:\n",
    "            vec.extend(e['query'][dim])\n",
    "        vec.append(e['error'])\n",
    "        features.append(vec)\n",
    "    features = np.array(features)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    \n",
    "    # Greedy selection\n",
    "    selected = [0]  # start with first\n",
    "    while len(selected) < k:\n",
    "        dists = euclidean_distances(features[selected], features)\n",
    "        min_dists = dists.min(axis=0)\n",
    "        next_idx = np.argmax(min_dists)\n",
    "        selected.append(next_idx)\n",
    "    return [entries[i] for i in selected]\n",
    "\n",
    "# Use diversified log for better model/training\n",
    "diversified_log = diversify_query_log(query_log, k=1000)\n",
    "# Retrain model on diversified_log if desired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce86dd",
   "metadata": {},
   "source": [
    "Extension 2: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def range_distance(q1, q2):\n",
    "    dist = 0\n",
    "    for dim in dimensions:\n",
    "        l1, u1 = q1[dim]\n",
    "        l2, u2 = q2[dim]\n",
    "        # IoU-style or Euclidean on bounds\n",
    "        dist += ((l1 - l2)**2 + (u1 - u2)**2)\n",
    "    return np.sqrt(dist)\n",
    "\n",
    "def optimized_similarity(alpha, val_queries):\n",
    "    errors = []\n",
    "    for vq in val_queries:\n",
    "        query = vq['query']\n",
    "        # predict error as before\n",
    "        vec = [...]  # flatten\n",
    "        pred_error = model.predict(scaler.transform([vec]))[0]\n",
    "        \n",
    "        best_entry = min(query_log, key=lambda e: \n",
    "            alpha * abs(e['error'] - pred_error) + \n",
    "            (1-alpha) * range_distance(query, e['query']))\n",
    "        \n",
    "        # compute LAQP estimate and relative error\n",
    "        # ... same as before ...\n",
    "        errors.append(rel_error)\n",
    "    return np.mean(errors)\n",
    "\n",
    "# Optimize alpha on validation queries\n",
    "res = minimize_scalar(lambda a: optimized_similarity(a, val_queries),\n",
    "                      bounds=(0,1), method='bounded')\n",
    "best_alpha = res.x\n",
    "print(f\"Best alpha: {best_alpha:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
